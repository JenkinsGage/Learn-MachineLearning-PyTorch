{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import os\n",
    "import pickle\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from pathlib import Path\n",
    "from torch import Tensor\n",
    "from torch.nn import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wmt19 (D:/Archives/HuggingfaceCache/datasets/wmt19/zh-en/1.0.0/29e210fae5690e843cae5dc43b53db36c4e02f927db50cd5235a22ab42dde90a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875f167763b64c348c8cfd18ac82d44f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 25984574\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['translation'],\n",
      "        num_rows: 3981\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Load translation dataset from huggingface\n",
    "os.environ['HF_DATASETS_OFFLINE'] = '1' # Comment this line if you need to download the dataset from huggingface\n",
    "dataset = load_dataset('wmt19', 'zh-en')\n",
    "print(dataset)\n",
    "SRC_LANGUAGE = 'zh'\n",
    "TGT_LANGUAGE = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "SUBSET_SIZE = 50000\n",
    "VOCAB_MIN_FREQ = 10\n",
    "\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "SPECIAL_SYMBOLS = ['<UNK>', '<PAD>', '<BOS>', '<EOS>']\n",
    "VOCAB_PATH = './Data/Vocab.pkl'\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 15\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab(en) Size: 7884\n",
      "Vocab(zh) Size: 7751\n"
     ]
    }
   ],
   "source": [
    "# Make token transformers that can be used to tokenize text into list of tokens(words).\n",
    "# I use the basic english tokenizer from torchtext for English.\n",
    "# And use jieba for Chinese.\n",
    "token_transform = {}\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('basic_english')\n",
    "token_transform[SRC_LANGUAGE] = lambda text: ([x for x in jieba.lcut(text) if x not in {' ', '\\t'}])\n",
    "\n",
    "# test_sentence_zh = '但后来他们逐渐意识到所探测到的信号可能完全来源于星际尘埃。'\n",
    "# test_sentence_en = 'It was later realized that the signal they had detected could be entirely attributed to interstellar dust.'\n",
    "# assert token_transform[SRC_LANGUAGE](test_sentence_zh) == ['但', '后来', '他们', '逐渐', '意识', '到', '所', '探测', '到', '的', '信号', '可能', '完全', '来源于', '星际', '尘埃', '。']\n",
    "# assert token_transform[TGT_LANGUAGE](test_sentence_en) == ['it', 'was', 'later', 'realized', 'that', 'the', 'signal', 'they', 'had', 'detected', 'could', 'be', 'entirely', 'attributed', 'to', 'interstellar', 'dust', '.']\n",
    "\n",
    "# Yield tokens from data iterator. For each data {'en':'...', 'zh':'...'} in data_iter, yield a list of tokens in corresponding language using token_transform.\n",
    "def yield_tokens(data_iter, language):\n",
    "    for data in data_iter:\n",
    "        yield token_transform[language](data[language])\n",
    "\n",
    "# Build the vocabulary that can be used to encode token(word) into integer.\n",
    "if Path(VOCAB_PATH).exists():\n",
    "    # If we already have the vocab, load it\n",
    "    with open(VOCAB_PATH, 'rb') as f:\n",
    "        vocab_transform = pickle.load(f)\n",
    "else:\n",
    "    # Otherwise, build the vocab\n",
    "    vocab_transform = {}\n",
    "    for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "        train_iter = iter(dataset['train'][:SUBSET_SIZE]['translation'])\n",
    "        vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln), min_freq=VOCAB_MIN_FREQ, specials=SPECIAL_SYMBOLS, special_first=True)\n",
    "    for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "        vocab_transform[ln].set_default_index(UNK_IDX)\n",
    "    with open(VOCAB_PATH, 'wb') as f:\n",
    "        pickle.dump(vocab_transform, f)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "print(f'Vocab({TGT_LANGUAGE}) Size: {TGT_VOCAB_SIZE}')\n",
    "print(f'Vocab({SRC_LANGUAGE}) Size: {SRC_VOCAB_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to make the real tokenizer that can tokenize a string of text into a sequence of integer tensors.\n",
    "\n",
    "# Helper function that passes a string into a list of transforms.\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# Helper function that adds a BOS and EOS token to a list of tokens. E.g. [BOS_IDX, 5, 7, ..., 456, EOS_IDX]\n",
    "def tensor_transform(token_ids):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# The real tokenizer.\n",
    "tokenizer = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    tokenizer[ln] = sequential_transforms(token_transform[ln], vocab_transform[ln], tensor_transform)\n",
    "\n",
    "# print(tokenizer[TGT_LANGUAGE](test_sentence_en))\n",
    "# Output:\n",
    "# tensor([   2,   17,   38,  660, 3413,   12,    5, 3510,   37,  103,    0,   60, 18, 1667, 4340,    7,    0, 5568,    6,    3])\n",
    "\n",
    "# print(tokenizer[SRC_LANGUAGE](test_sentence_zh))\n",
    "# Output:\n",
    "# tensor([   2,   13, 2221,   36,  843, 1092,   47,   49,    0,   47,    4, 1358, 37,  361, 3490,    0,    0,    6,    3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 50000\n",
      "Validation dataset size: 3981\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(tokenizer[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(tokenizer[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "class WMT19Dataset(Dataset):\n",
    "    def __init__(self, dataset, subset_size = None):\n",
    "        self.dataset = dataset\n",
    "        self.subset_size = subset_size\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.subset_size is None:\n",
    "            return len(self.dataset)\n",
    "        return self.subset_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]['translation'][SRC_LANGUAGE], self.dataset[idx]['translation'][TGT_LANGUAGE]\n",
    "    \n",
    "train_dataset = WMT19Dataset(dataset['train'], SUBSET_SIZE)\n",
    "valid_dataset = WMT19Dataset(dataset['validation'])\n",
    "\n",
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Validation dataset size: {len(valid_dataset)}')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer implementation from https://pytorch.org/tutorials/beginner/translation_transformer.html\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)\n",
    "    \n",
    "    \n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: 24.67M Seq2SeqTransformer(\n",
      "  (transformer): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-2): 3 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-2): 3 x TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "          (dropout3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=512, out_features=7884, bias=True)\n",
      "  (src_tok_emb): TokenEmbedding(\n",
      "    (embedding): Embedding(7751, 512)\n",
      "  )\n",
      "  (tgt_tok_emb): TokenEmbedding(\n",
      "    (embedding): Embedding(7884, 512)\n",
      "  )\n",
      "  (positional_encoding): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transformer = Seq2SeqTransformer(num_encoder_layers=NUM_ENCODER_LAYERS, num_decoder_layers=NUM_DECODER_LAYERS, emb_size=EMB_SIZE, nhead=NHEAD, src_vocab_size=SRC_VOCAB_SIZE, tgt_vocab_size=TGT_VOCAB_SIZE, dim_feedforward=FFN_HID_DIM, dropout=DROPOUT)\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "print(f'Model params: {sum(p.numel() for p in transformer.parameters() if p.requires_grad)/1000000:.2f}M', transformer)\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = torch.optim.AdamW(transformer.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    \n",
    "    total_steps = 0\n",
    "    for src, tgt in tqdm(train_dataloader):\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "        tgt_input = tgt[:-1, :]\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        total_steps += 1\n",
    "    return losses / total_steps\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    total_steps = 0\n",
    "    for src, tgt in valid_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "        total_steps += 1\n",
    "    return losses / total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Start epoch 1/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e5179e3e8643eca2cb8f0375ed707d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\indie\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.341 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "e:\\Software\\Miniconda\\envs\\ml-torch\\lib\\site-packages\\torch\\nn\\functional.py:4999: UserWarning: Support for mismatched src_key_padding_mask and src_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "e:\\Software\\Miniconda\\envs\\ml-torch\\lib\\site-packages\\torch\\nn\\functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 1| Train loss: 5.796, Val loss: 5.287, Epoch time = 61.795s\n",
      "----------------------------------------\n",
      "Start epoch 2/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29859090110e4dcba9d3a200fd94a159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 2| Train loss: 5.038, Val loss: 4.962, Epoch time = 69.040s\n",
      "----------------------------------------\n",
      "Start epoch 3/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af98e5d87ace41428b1232cb55dc6f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 3| Train loss: 4.618, Val loss: 4.758, Epoch time = 69.952s\n",
      "----------------------------------------\n",
      "Start epoch 4/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8bb60850c164b20a52940777270229c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 4| Train loss: 4.271, Val loss: 4.632, Epoch time = 82.099s\n",
      "----------------------------------------\n",
      "Start epoch 5/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931210eb6f7a426cb201dd730bd16218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 5| Train loss: 3.984, Val loss: 4.528, Epoch time = 85.065s\n",
      "----------------------------------------\n",
      "Start epoch 6/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4e86678990e4c0fab5476fabff58cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 6| Train loss: 3.737, Val loss: 4.441, Epoch time = 80.296s\n",
      "----------------------------------------\n",
      "Start epoch 7/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8990ce7cf8d94059ab82e75c7f129cf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 7| Train loss: 3.524, Val loss: 4.364, Epoch time = 74.471s\n",
      "----------------------------------------\n",
      "Start epoch 8/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab628c0a1b374c578944a6964541e0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 8| Train loss: 3.336, Val loss: 4.293, Epoch time = 75.040s\n",
      "----------------------------------------\n",
      "Start epoch 9/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f6c57e466ba407395e8d08c1257f838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 9| Train loss: 3.172, Val loss: 4.243, Epoch time = 75.364s\n",
      "----------------------------------------\n",
      "Start epoch 10/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2e89306b9e4c92840baa4e518f7c19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 10| Train loss: 3.030, Val loss: 4.244, Epoch time = 74.732s\n",
      "----------------------------------------\n",
      "Start epoch 11/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c20234b42ee04a419c19cdb3bbc5492f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 11| Train loss: 2.901, Val loss: 4.217, Epoch time = 74.914s\n",
      "----------------------------------------\n",
      "Start epoch 12/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c114b5ba462f4fcc9d15e2b2de4971d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 12| Train loss: 2.788, Val loss: 4.226, Epoch time = 75.426s\n",
      "----------------------------------------\n",
      "Start epoch 13/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e3ad7782307496f9b4e52ffc24c3a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 13| Train loss: 2.687, Val loss: 4.209, Epoch time = 75.306s\n",
      "----------------------------------------\n",
      "Start epoch 14/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebedff517be4442a84d9171d8d1a9c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 14| Train loss: 2.597, Val loss: 4.207, Epoch time = 74.973s\n",
      "----------------------------------------\n",
      "Start epoch 15/15\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342bae33f8ee44aeb7b3d3a94c8d92b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 15| Train loss: 2.514, Val loss: 4.216, Epoch time = 74.523s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = timer()\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Start epoch {}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    print(\"-\" * 40)\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    torch.save(transformer.state_dict(), './Model/Transformer.pth')\n",
    "    print((f\"Finished epoch: {epoch + 1}| Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, Epoch time = {(end_time - start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "def beam_search(model, src, src_mask, max_len, start_symbol, beam_size=3):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    beam = [(ys, 0)]\n",
    "    for i in range(max_len-1):\n",
    "        candidates = []\n",
    "        for snt, score in beam:\n",
    "            if snt[0][-1] == EOS_IDX:\n",
    "                candidates.append((snt, score))\n",
    "                continue\n",
    "            memory = memory.to(DEVICE)\n",
    "            tgt_mask = (generate_square_subsequent_mask(snt.size(0))\n",
    "                        .type(torch.bool)).to(DEVICE)\n",
    "            out = model.decode(snt, memory, tgt_mask)\n",
    "            out = out.transpose(0, 1)\n",
    "            prob = model.generator(out[:, -1])\n",
    "            topk = torch.topk(prob, beam_size)\n",
    "            for next_word, word_score in zip(topk.indices[0], topk.values[0]):\n",
    "                next_word = next_word.item()\n",
    "                word_score = word_score.item()\n",
    "                candidate = (torch.cat([snt,\n",
    "                                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0),\n",
    "                             score + word_score)\n",
    "                candidates.append(candidate)\n",
    "        beam = sorted(candidates, key=lambda x: x[1], reverse=True)[:beam_size]\n",
    "    return beam[0][0]\n",
    "\n",
    "def translate(model: torch.nn.Module, src_sentence: str, use_beam_search=False):\n",
    "    model.eval()\n",
    "    src = tokenizer[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    if use_beam_search:\n",
    "        tgt_tokens = beam_search(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX, beam_size=5).flatten()\n",
    "    else:\n",
    "        tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<BOS>\", \"\").replace(\"<EOS>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Src: 上周，古装剧《美人私房菜》临时停播，意外引发了关于国产剧收视率造假的热烈讨论。\n",
      "Truth: Last week, the broadcast of period drama “Beauty Private Kitchen” was temporarily halted, and accidentally triggered heated debate about faked ratings of locally produced dramas.\n",
      "Translation:  last week , the third plenum of the <UNK> <UNK> composite index , has been a <UNK> discussion of discussion about <UNK> .  . ”  . \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: 民权团体针对密苏里州发出旅行警告\n",
      "Truth: Civil rights group issues travel warning for Missouri\n",
      "Translation:  <UNK> groups have warned in <UNK> .      \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: 由于密苏里州的歧视性政策和种族主义袭击，美国有色人种促进协会 (NAACP) 向准备前往密苏里州出游的有色人群发出旅行警告。\n",
      "Truth: The National Association for the Advancement of Colored People has put out an alert for people of color traveling to Missouri because of the state's discriminatory policies and racist attacks.\n",
      "Translation:  thanks to its <UNK> policies and racist attacks , the united states is prepared to engineer a letter to the middle class to travel into <UNK> <UNK> .  .   . \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: “2017 年 8 月 28 日生效的 NAACP 密苏里州旅行咨询中呼吁，因近期密苏里州发生了一系列可疑的种族性事件，所有非裔美籍旅行者、游客以及密苏里州人在密苏里州旅行时应特别注意并采取极其谨慎的态度，特此告知，”该团体的声明宣称。\n",
      "Truth: \"The NAACP Travel Advisory for the state of Missouri, effective through August 28th, 2017, calls for African American travelers, visitors and Missourians to pay special attention and exercise extreme caution when traveling throughout the state given the series of questionable, race-based incidents occurring statewide recently, and noted therein,\" the group's statement reads.\n",
      "Translation:  in august 2017 , the call for a series of racial <UNK> in august 2017 was called for a series of racial <UNK> , <UNK> <UNK> , <UNK> , <UNK> , and <UNK> <UNK> <UNK> , <UNK> , and <UNK> <UNK> . ”  to speak out of <UNK> , ”  . ”  said to say , ”  . ”  . \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: NAACP 指出，最近通过的一项密苏里州法律使得人们更难赢得歧视诉讼，该州执法也一定程度上针对少数群体，这些现象促使该组织发布了旅行警告。\n",
      "Truth: A recent Missouri law making it harder for people to win discrimination lawsuits, as well as the state's law enforcement disproportionately targeting minorities prompted the group to issue the travel alert, the NAACP said.\n",
      "Translation:  <UNK> pointed out that the recent legal law allows people to win discrimination against discrimination against minorities , the state enforcement of state law has also been warning of minorities .  in the organization of the organization .  warned that\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: 侵犯公民权利的行为正发生在人们身上。\n",
      "Truth: \"You have violations of civil rights that are happening to people.\n",
      "Translation:  <UNK> behavior is happening .  .  .   .   . \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: 他们因肤色被停车盘问，被殴打或被杀害，”密苏里州 NAACP 主席罗德·查培尔告诉堪萨斯城星报 (The Kansas City Star)。\n",
      "Truth: They're being pulled over because of their skin color, they're being beaten up or killed,\" the president of the Missouri NAACP, Rod Chapel, told The Kansas City Star.\n",
      "Translation:  they were treated as <UNK> or killed , <UNK> , ” as president <UNK> <UNK> <UNK> told , ” president mike <UNK> tell the <UNK> <UNK> . )  .  .  .  . \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: “我们收到了许多投诉，数量前所未有。”\n",
      "Truth: \"We are hearing complaints at a rate we haven't heard before.\"\n",
      "Translation:  “we have <UNK> many of them , 000 . ”  . ”  . ” \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: 这是该组织在美国针对某个州发布的第一个此类警告。\n",
      "Truth: It is the first such warning that the organization has issued for a state in the US.\n",
      "Translation:  this is the first warning of the united states .  .  .   .   . \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: 该组织援引了密苏里大学对黑人学生的种族诽谤以及 28 岁田纳西州黑人男性托利·桑德斯的死亡事件。\n",
      "Truth: The group cited incidents such as racial slurs against black students at the University of Missouri and the death of Tory Sanders, 28, a black man from Tennessee.\n",
      "Translation:  the organization <UNK> the <UNK> of the university of the university of <UNK> students in black students , and 28 , 000 men who died .  .  . \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: 今年早些时候，桑德斯在可疑情况下死亡。他在密苏里州旅行时燃油耗尽，被密苏里州警方在无指控犯罪的情况下拘留。\n",
      "Truth: Sanders died under questionable circumstances earlier this year after he ran out of gas while traveling through the state, and was taken into custody by Missouri police without being accused of a crime.\n",
      "Translation:  earlier this year later , <UNK> died when he was arrested when he was arrested when the police trial were arrested .  under trial .  .  .  .   . \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: 咨询中还指出，密苏里州总检察长办公室最近的一份报告显示，“与白人相比，该州的黑人司机被停车盘查的可能性要高出 75%”。\n",
      "Truth: The advisory also points to a recent report by the Missouri Attorney General's Office showing that black drivers in the state were 75 percent more likely to be pulled over than whites.\n",
      "Translation:  <UNK> also pointed out that the number of dollars was recently released by the fourth quarter of 2013 , ” the <UNK> driver of the <UNK> driver of the white house was <UNK> . ” ”  , ” \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: 查培尔说：“该份咨询是为了提高人们的意识，警告他们的家人、朋友和同事在密苏里州可能发生的情况。”\n",
      "Truth: \"The advisory is for people to be aware, and warn their families and friends and co-workers of what could happen in Missouri,\" Chapel said.\n",
      "Translation:  liu <UNK> said that <UNK> <UNK> was intended to boost people , warning , friends , friends , friends , and colleagues are likely to occur . ”  . ” ” ”  . ”\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: “人们需要做好准备，无论是携带保释金前往密苏里州，还是让亲属知道自己在州内旅行”。\n",
      "Truth: \"People need to be ready, whether it's bringing bail money with them, or letting relatives know they are traveling through the state.\"\n",
      "Translation:  “we need to be prepared to be prepared , whether they are able to retain access , or allow hundreds of thousands of people who know themselves . ”\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: 根据联邦调查局仇恨犯罪报告计划的最新数据，密苏里州在 2015 年记录了 100 起仇恨罪行；根据罪行量，该州在全国排名第 16 位。\n",
      "Truth: Missouri recorded 100 hate crimes in 2015, according to the latest figures from the FBI's hate crime reporting program, ranking the state at 16th in the country in terms of the number of such violations.\n",
      "Translation:  according to a recent study against the fbi report , the <UNK> <UNK> of crime in 2015 was released according to the islamic state , the state department , according to the islamic state . ”  in\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: 旅行警告也是对密苏里州新法律的回应，该法律将使起诉住房或就业歧视企业变得更加困难。\n",
      "Truth: The travel warning is also a response to a new Missouri law that would make it more difficult to sue a business for housing or employment discrimination.\n",
      "Translation:  los angeles has also responded positively to new law , the law would enable <UNK> housing , or job discrimination .   .  .  .  . \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: 此前，美国各州通过了移民执法法律，要求当地执法部门拘留移民违规人员，美国公民自由联盟 (ACLU) 表示此举会增加种族诉讼数量，并发布了针对德克萨斯州和亚利桑那州的旅行咨询。\n",
      "Truth: Previously, the American Civil Liberties Union (ACLU) had issued travel advisories for Texas and Arizona after the states passed immigration enforcement laws requiring local law enforcement to detain people on immigration violations which the ACLU said would increase racial profiling.\n",
      "Translation:  previously , the united states has <UNK> immigration laws through immigration enforcement , requiring local enforcement of migrant workers , the united states’ civil liberties civil liberties program ( <UNK> ) , which would increase racial <UNK> and <UNK> <UNK> .  in jail and <UNK> <UNK> . ” \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: 旅行警告通常是由美国政府针对其他国家发布的，但最近，咨询团体采取这一方式以应对美国境内的某些法律和趋势。\n",
      "Truth: Travel warnings are usually issued by the State Department for other countries, but lately, advocacy groups have resorted to the measure in response to certain laws and trends inside the US.\n",
      "Translation:  travel was usually released by the us government in other countries , but the recent decision to address this approach to dealing with some legal trends and trends .  in the united states . \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: 经历2015年票房猛增的“黄金时代”后，2016年整体电影市场进入了冷静期，能否突破去年440.69亿元的总票房成绩都成为一个悬念。\n",
      "Truth: After experiencing the “golden era” of a soaring box office in 2015, the film market retreated into a cooling-off period in 2016. Whether box office takings could surpass last year’s total of RMB44.069 billion is questionable.\n",
      "Translation:  twenty years after 2015 , ” the overall global market in 2016 has entered a third quarter of 2008 , regardless of whether a breakthrough in the last year .  results have become a <UNK> .  . ” \n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "Src: 从国家统计局公布的数据看，10月，北京新房和二手房价格双双降温，环比仅上涨0.6%和1.1%。\n",
      "Truth: Data from the National Bureau of Statistics revealed that in October, prices of new and second-hand residential properties cooled, up 0.6% and 1.1% month-on-month, respectively.\n",
      "Translation:  according to <UNK> data , beijing was scheduled in beijing in beijing and <UNK> prices , just 0 . 8% and <UNK> .  .  in beijing .  \n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "NUM_TEST = 20\n",
    "for i in range(NUM_TEST):\n",
    "    src, truth = valid_dataset[i]\n",
    "    translation = translate(transformer, src, True)\n",
    "    print('-'*40)\n",
    "    print(f'Src: {src}')\n",
    "    print(f'Truth: {truth}')\n",
    "    print(f'Translation: {translation}')\n",
    "    print('-'*40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c83d32d8d11e19a2b0b75a6f97d6cd500aaf83e0be40dc743eb8d42a580816ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
