{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import os\n",
    "import pickle\n",
    "import math\n",
    "from tqdm.notebook import tqdm\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from pathlib import Path\n",
    "from torch import Tensor\n",
    "from torch.nn import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load translation dataset from huggingface\n",
    "os.environ['HF_DATASETS_OFFLINE'] = '1' # Comment this line if you need to download the dataset from huggingface\n",
    "dataset = load_dataset('wmt19', 'zh-en')\n",
    "print(dataset)\n",
    "SRC_LANGUAGE = 'zh'\n",
    "TGT_LANGUAGE = 'en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters\n",
    "SUBSET_SIZE = 50000\n",
    "VOCAB_MIN_FREQ = 10\n",
    "\n",
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "SPECIAL_SYMBOLS = ['<UNK>', '<PAD>', '<BOS>', '<EOS>']\n",
    "VOCAB_PATH = './Data/Vocab.pkl'\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_EPOCHS = 30\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EMB_SIZE = 512\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "NUM_ENCODER_LAYERS = 3\n",
    "NUM_DECODER_LAYERS = 3\n",
    "DROPOUT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab(en) Size: 7884\n",
      "Vocab(zh) Size: 7751\n"
     ]
    }
   ],
   "source": [
    "# Make token transformers that can be used to tokenize text into list of tokens(words).\n",
    "# I use the basic english tokenizer from torchtext for English.\n",
    "# And use jieba for Chinese.\n",
    "token_transform = {}\n",
    "token_transform[TGT_LANGUAGE] = get_tokenizer('basic_english')\n",
    "token_transform[SRC_LANGUAGE] = lambda text: ([x for x in jieba.lcut(text) if x not in {' ', '\\t'}])\n",
    "\n",
    "# test_sentence_zh = '但后来他们逐渐意识到所探测到的信号可能完全来源于星际尘埃。'\n",
    "# test_sentence_en = 'It was later realized that the signal they had detected could be entirely attributed to interstellar dust.'\n",
    "# assert token_transform[SRC_LANGUAGE](test_sentence_zh) == ['但', '后来', '他们', '逐渐', '意识', '到', '所', '探测', '到', '的', '信号', '可能', '完全', '来源于', '星际', '尘埃', '。']\n",
    "# assert token_transform[TGT_LANGUAGE](test_sentence_en) == ['it', 'was', 'later', 'realized', 'that', 'the', 'signal', 'they', 'had', 'detected', 'could', 'be', 'entirely', 'attributed', 'to', 'interstellar', 'dust', '.']\n",
    "\n",
    "# Yield tokens from data iterator. For each data {'en':'...', 'zh':'...'} in data_iter, yield a list of tokens in corresponding language using token_transform.\n",
    "def yield_tokens(data_iter, language):\n",
    "    for data in data_iter:\n",
    "        yield token_transform[language](data[language])\n",
    "\n",
    "# Build the vocabulary that can be used to encode token(word) into integer.\n",
    "if Path(VOCAB_PATH).exists():\n",
    "    # If we already have the vocab, load it\n",
    "    with open(VOCAB_PATH, 'rb') as f:\n",
    "        vocab_transform = pickle.load(f)\n",
    "else:\n",
    "    # Otherwise, build the vocab\n",
    "    vocab_transform = {}\n",
    "    for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "        train_iter = iter(dataset['train'][:SUBSET_SIZE]['translation'])\n",
    "        vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln), min_freq=VOCAB_MIN_FREQ, specials=SPECIAL_SYMBOLS, special_first=True)\n",
    "    for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "        vocab_transform[ln].set_default_index(UNK_IDX)\n",
    "    with open(VOCAB_PATH, 'wb') as f:\n",
    "        pickle.dump(vocab_transform, f)\n",
    "\n",
    "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
    "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
    "print(f'Vocab({TGT_LANGUAGE}) Size: {TGT_VOCAB_SIZE}')\n",
    "print(f'Vocab({SRC_LANGUAGE}) Size: {SRC_VOCAB_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need to make the real tokenizer that can tokenize a string of text into a sequence of integer tensors.\n",
    "\n",
    "# Helper function that passes a string into a list of transforms.\n",
    "def sequential_transforms(*transforms):\n",
    "    def func(txt_input):\n",
    "        for transform in transforms:\n",
    "            txt_input = transform(txt_input)\n",
    "        return txt_input\n",
    "    return func\n",
    "\n",
    "# Helper function that adds a BOS and EOS token to a list of tokens. E.g. [BOS_IDX, 5, 7, ..., 456, EOS_IDX]\n",
    "def tensor_transform(token_ids):\n",
    "    return torch.cat((torch.tensor([BOS_IDX]),\n",
    "                      torch.tensor(token_ids),\n",
    "                      torch.tensor([EOS_IDX])))\n",
    "\n",
    "# The real tokenizer.\n",
    "tokenizer = {}\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    tokenizer[ln] = sequential_transforms(token_transform[ln], vocab_transform[ln], tensor_transform)\n",
    "\n",
    "# print(tokenizer[TGT_LANGUAGE](test_sentence_en))\n",
    "# Output:\n",
    "# tensor([   2,   17,   38,  660, 3413,   12,    5, 3510,   37,  103,    0,   60, 18, 1667, 4340,    7,    0, 5568,    6,    3])\n",
    "\n",
    "# print(tokenizer[SRC_LANGUAGE](test_sentence_zh))\n",
    "# Output:\n",
    "# tensor([   2,   13, 2221,   36,  843, 1092,   47,   49,    0,   47,    4, 1358, 37,  361, 3490,    0,    0,    6,    3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 50000\n",
      "Validation dataset size: 3981\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tgt_batch = [], []\n",
    "    for src_sample, tgt_sample in batch:\n",
    "        src_batch.append(tokenizer[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
    "        tgt_batch.append(tokenizer[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
    "\n",
    "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
    "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
    "    return src_batch, tgt_batch\n",
    "\n",
    "class WMT19Dataset(Dataset):\n",
    "    def __init__(self, dataset, subset_size = None):\n",
    "        self.dataset = dataset\n",
    "        self.subset_size = subset_size\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.subset_size is None:\n",
    "            return len(self.dataset)\n",
    "        return self.subset_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx]['translation'][SRC_LANGUAGE], self.dataset[idx]['translation'][TGT_LANGUAGE]\n",
    "    \n",
    "train_dataset = WMT19Dataset(dataset['train'], SUBSET_SIZE)\n",
    "valid_dataset = WMT19Dataset(dataset['validation'])\n",
    "\n",
    "print(f'Train dataset size: {len(train_dataset)}')\n",
    "print(f'Validation dataset size: {len(valid_dataset)}')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer implementation from https://pytorch.org/tutorials/beginner/translation_transformer.html\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size,\n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)\n",
    "    \n",
    "    \n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: 12.48M Seq2SeqTransformer(\n",
      "  (transformer): Transformer(\n",
      "    (encoder): TransformerEncoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-2): 3 x TransformerEncoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): TransformerDecoder(\n",
      "      (layers): ModuleList(\n",
      "        (0-2): 3 x TransformerDecoderLayer(\n",
      "          (self_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
      "          )\n",
      "          (multihead_attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=320, out_features=320, bias=True)\n",
      "          )\n",
      "          (linear1): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (dropout): Dropout(p=0.2, inplace=False)\n",
      "          (linear2): Linear(in_features=320, out_features=320, bias=True)\n",
      "          (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "          (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "          (dropout1): Dropout(p=0.2, inplace=False)\n",
      "          (dropout2): Dropout(p=0.2, inplace=False)\n",
      "          (dropout3): Dropout(p=0.2, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (generator): Linear(in_features=320, out_features=7884, bias=True)\n",
      "  (src_tok_emb): TokenEmbedding(\n",
      "    (embedding): Embedding(7751, 320)\n",
      "  )\n",
      "  (tgt_tok_emb): TokenEmbedding(\n",
      "    (embedding): Embedding(7884, 320)\n",
      "  )\n",
      "  (positional_encoding): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.2, inplace=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "transformer = Seq2SeqTransformer(num_encoder_layers=NUM_ENCODER_LAYERS, num_decoder_layers=NUM_DECODER_LAYERS, emb_size=EMB_SIZE, nhead=NHEAD, src_vocab_size=SRC_VOCAB_SIZE, tgt_vocab_size=TGT_VOCAB_SIZE, dim_feedforward=FFN_HID_DIM, dropout=DROPOUT)\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "print(f'Model params: {sum(p.numel() for p in transformer.parameters() if p.requires_grad)/1000000:.2f}M', transformer)\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "optimizer = torch.optim.AdamW(transformer.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    losses = 0\n",
    "    \n",
    "    total_steps = 0\n",
    "    for src, tgt in tqdm(train_dataloader):\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "        tgt_input = tgt[:-1, :]\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        total_steps += 1\n",
    "    return losses / total_steps\n",
    "\n",
    "\n",
    "def evaluate(model):\n",
    "    model.eval()\n",
    "    losses = 0\n",
    "\n",
    "    total_steps = 0\n",
    "    for src, tgt in valid_dataloader:\n",
    "        src = src.to(DEVICE)\n",
    "        tgt = tgt.to(DEVICE)\n",
    "\n",
    "        tgt_input = tgt[:-1, :]\n",
    "\n",
    "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
    "\n",
    "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
    "\n",
    "        tgt_out = tgt[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        losses += loss.item()\n",
    "        total_steps += 1\n",
    "    return losses / total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Start epoch 1/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c14bf667bc44ea848cb93bf543c0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Software\\Miniconda\\envs\\ml-torch\\lib\\site-packages\\torch\\nn\\functional.py:4999: UserWarning: Support for mismatched src_key_padding_mask and src_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n",
      "e:\\Software\\Miniconda\\envs\\ml-torch\\lib\\site-packages\\torch\\nn\\functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 0| Train loss: 6.025, Val loss: 5.441, Epoch time = 49.769s\n",
      "----------------------------------------\n",
      "Start epoch 2/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cb0caedf5ea44298a47497b84bda5d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 1| Train loss: 5.263, Val loss: 5.166, Epoch time = 56.024s\n",
      "----------------------------------------\n",
      "Start epoch 3/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d26d35e1ec4f5a9ef45e7d79fd5fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 2| Train loss: 4.947, Val loss: 4.970, Epoch time = 51.476s\n",
      "----------------------------------------\n",
      "Start epoch 4/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9ac6f79c8d14f16b11967ee5a51cedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 3| Train loss: 4.677, Val loss: 4.829, Epoch time = 50.682s\n",
      "----------------------------------------\n",
      "Start epoch 5/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f242f9d05db43278083664e4537a3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 4| Train loss: 4.440, Val loss: 4.724, Epoch time = 49.939s\n",
      "----------------------------------------\n",
      "Start epoch 6/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1762b06b0c4d2a86e4da293a1de42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 5| Train loss: 4.232, Val loss: 4.644, Epoch time = 50.298s\n",
      "----------------------------------------\n",
      "Start epoch 7/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd4e7f0b60a549d1ab1307edfa335c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 6| Train loss: 4.051, Val loss: 4.570, Epoch time = 59.224s\n",
      "----------------------------------------\n",
      "Start epoch 8/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a04aa434c5d43d39ce177d1d8c13f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 7| Train loss: 3.888, Val loss: 4.507, Epoch time = 52.911s\n",
      "----------------------------------------\n",
      "Start epoch 9/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575b01230dc24ad194464aabfe89b5dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 8| Train loss: 3.741, Val loss: 4.464, Epoch time = 51.849s\n",
      "----------------------------------------\n",
      "Start epoch 10/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0e5dfed4ab49cebb15e0ec19c9cf12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 9| Train loss: 3.606, Val loss: 4.396, Epoch time = 49.562s\n",
      "----------------------------------------\n",
      "Start epoch 11/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f0b2afbfac46d4bc58734074e1a0ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 10| Train loss: 3.479, Val loss: 4.367, Epoch time = 45.527s\n",
      "----------------------------------------\n",
      "Start epoch 12/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e736e56061104d7ca57753d372351b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 11| Train loss: 3.365, Val loss: 4.343, Epoch time = 43.043s\n",
      "----------------------------------------\n",
      "Start epoch 13/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd4bcd66e9241f6a290a844483f2316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 12| Train loss: 3.258, Val loss: 4.306, Epoch time = 42.869s\n",
      "----------------------------------------\n",
      "Start epoch 14/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e96b99f40f411e9d2a4ac66da5e0b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 13| Train loss: 3.159, Val loss: 4.273, Epoch time = 45.048s\n",
      "----------------------------------------\n",
      "Start epoch 15/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f87ab3bc7642425bb6ea0c1ed615316a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 14| Train loss: 3.068, Val loss: 4.275, Epoch time = 46.341s\n",
      "----------------------------------------\n",
      "Start epoch 16/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cb826477a5b4124b965fa1179da1208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 15| Train loss: 2.985, Val loss: 4.224, Epoch time = 45.137s\n",
      "----------------------------------------\n",
      "Start epoch 17/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eac7728370c4351ba03ab3ef7096829",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 16| Train loss: 2.909, Val loss: 4.214, Epoch time = 44.411s\n",
      "----------------------------------------\n",
      "Start epoch 18/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4187dbdbdeb1440ca45de9ad6c74685e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 17| Train loss: 2.838, Val loss: 4.200, Epoch time = 45.799s\n",
      "----------------------------------------\n",
      "Start epoch 19/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f70ce8e30674a1d8cf69225e590d4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 18| Train loss: 2.773, Val loss: 4.198, Epoch time = 49.604s\n",
      "----------------------------------------\n",
      "Start epoch 20/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f792ba1ede4ba6aff87da9f9461a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 19| Train loss: 2.713, Val loss: 4.196, Epoch time = 46.508s\n",
      "----------------------------------------\n",
      "Start epoch 21/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ab3e4662ad4903afba027e68ec4a9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 20| Train loss: 2.654, Val loss: 4.165, Epoch time = 46.593s\n",
      "----------------------------------------\n",
      "Start epoch 22/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a34a5989594e7f8c8b86f818c2e921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 21| Train loss: 2.602, Val loss: 4.167, Epoch time = 49.548s\n",
      "----------------------------------------\n",
      "Start epoch 23/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba7d0b9c860745afa62541d8d92c1a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 22| Train loss: 2.552, Val loss: 4.176, Epoch time = 48.598s\n",
      "----------------------------------------\n",
      "Start epoch 24/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee62aa9d08784de4a3624904e6e0fbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 23| Train loss: 2.506, Val loss: 4.162, Epoch time = 47.065s\n",
      "----------------------------------------\n",
      "Start epoch 25/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737d4419b3e04012bdb9abfa218bbefa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 24| Train loss: 2.462, Val loss: 4.149, Epoch time = 43.654s\n",
      "----------------------------------------\n",
      "Start epoch 26/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2f6e4c78c9470e8b38e267ef3078a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 25| Train loss: 2.420, Val loss: 4.161, Epoch time = 43.171s\n",
      "----------------------------------------\n",
      "Start epoch 27/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c618e397fd0f4c1da00d6091275ba86e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 26| Train loss: 2.380, Val loss: 4.151, Epoch time = 51.106s\n",
      "----------------------------------------\n",
      "Start epoch 28/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90147ef77f874f96b007f8bf9dcb7630",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 27| Train loss: 2.342, Val loss: 4.158, Epoch time = 54.609s\n",
      "----------------------------------------\n",
      "Start epoch 29/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b61c4ff16adc4f3a83517e3a6d28306a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 28| Train loss: 2.307, Val loss: 4.168, Epoch time = 52.735s\n",
      "----------------------------------------\n",
      "Start epoch 30/30\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f5a6e3ec3949d689736c67df373637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/782 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch: 29| Train loss: 2.271, Val loss: 4.169, Epoch time = 53.055s\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = timer()\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Start epoch {}/{}\".format(epoch + 1, NUM_EPOCHS))\n",
    "    print(\"-\" * 40)\n",
    "    train_loss = train_epoch(transformer, optimizer)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer)\n",
    "    print((f\"Finished epoch: {epoch + 1}| Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, Epoch time = {(end_time - start_time):.3f}s\"))\n",
    "\n",
    "torch.save(transformer.state_dict(), './Model/Transformer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
    "                    .type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim=1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "def beam_search(model, src, src_mask, max_len, start_symbol, beam_size=3):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    beam = [(ys, 0)]\n",
    "    for i in range(max_len-1):\n",
    "        candidates = []\n",
    "        for snt, score in beam:\n",
    "            if snt[0][-1] == EOS_IDX:\n",
    "                candidates.append((snt, score))\n",
    "                continue\n",
    "            memory = memory.to(DEVICE)\n",
    "            tgt_mask = (generate_square_subsequent_mask(snt.size(0))\n",
    "                        .type(torch.bool)).to(DEVICE)\n",
    "            out = model.decode(snt, memory, tgt_mask)\n",
    "            out = out.transpose(0, 1)\n",
    "            prob = model.generator(out[:, -1])\n",
    "            topk = torch.topk(prob, beam_size)\n",
    "            for next_word, word_score in zip(topk.indices[0], topk.values[0]):\n",
    "                next_word = next_word.item()\n",
    "                word_score = word_score.item()\n",
    "                candidate = (torch.cat([snt,\n",
    "                                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0),\n",
    "                             score + word_score)\n",
    "                candidates.append(candidate)\n",
    "        beam = sorted(candidates, key=lambda x: x[1], reverse=True)[:beam_size]\n",
    "    return beam[0][0]\n",
    "\n",
    "def translate(model: torch.nn.Module, src_sentence: str, use_beam_search=False):\n",
    "    model.eval()\n",
    "    src = tokenizer[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
    "    num_tokens = src.shape[0]\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    if use_beam_search:\n",
    "        tgt_tokens = beam_search(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX, beam_size=5).flatten()\n",
    "    else:\n",
    "        tgt_tokens = greedy_decode(model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "\n",
    "    return \" \".join(vocab_transform[TGT_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<BOS>\", \"\").replace(\"<EOS>\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " you succeeded        \n"
     ]
    }
   ],
   "source": [
    "print(translate(transformer, '你成功了!', use_beam_search=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c83d32d8d11e19a2b0b75a6f97d6cd500aaf83e0be40dc743eb8d42a580816ed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
