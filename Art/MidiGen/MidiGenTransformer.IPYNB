{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A matching Triton is not available, some optimizations will not be enabled.\n",
      "Error caught was: No module named 'triton'\n",
      "Triton is not available, some optimizations will not be enabled.\n",
      "This is just a warning: No module named 'triton'\n",
      "Triton is not available, FusedMLP will not be enabled.\n",
      "Either FairScale or torch distributed is not available, MixtureOfExperts will not be exposed. Please install them if you would like to use MoE\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import ast\n",
    "from typing import Optional\n",
    "from dataclasses import dataclass\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from xformers.factory.model_factory import xFormer, xFormerConfig\n",
    "from xformers.components.positional_embedding import (PositionEmbedding, PositionEmbeddingConfig, register_positional_embedding)\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, Adafactor\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 128\n",
    "BOS_IDX = 129\n",
    "EOS_IDX = 130\n",
    "PAD_VALUE = 0.0\n",
    "\n",
    "NUM_ENCODER_LAYERS = 6\n",
    "NUM_DECODER_LAYERS = 6\n",
    "EMB_SIZE=64\n",
    "MAX_LEN = 256\n",
    "SRC_VOCAB_SIZE = 128+3 # 0-127 representing From C-1 to G9, 128 for PAD_IDX, 129 for BOS, 130 for EOS\n",
    "TGT_VOCAB_SIZE = 128+3\n",
    "NHEAD = 4\n",
    "HIDDEN_LAYER_MULTIPLIER = 4\n",
    "DROPOUT = 0.2\n",
    "\n",
    "TRAIN_SPLIT = 0.95\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # A GPU with memory >=8GB is capable of training\n",
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 7\n",
    "BATCH_SIZE = 64\n",
    "REPEATING_PENALTY = 32.0\n",
    "\n",
    "LOAD_PRETRAINED = False\n",
    "MODEL_SAVE_PATH = './Model/MidiGen.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MidiDataset(Dataset):\n",
    "    def __init__(self, csv_path='./Data/MidiDataset.csv'):\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - 2\n",
    "        # return 50000\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        current_row = self.data.loc[idx]\n",
    "        next_row = self.data.loc[idx+1]\n",
    "        return (\n",
    "            {\n",
    "                'sentence': current_row.at['Sentence'],\n",
    "                'time_since_last_note': current_row.at['TimeSinceLastNoteStart'],\n",
    "                'duration': current_row.at['Duration'],\n",
    "                'velocity': current_row.at['Velocity']\n",
    "            },\n",
    "            {\n",
    "                'sentence': next_row.at['Sentence'],\n",
    "                'time_since_last_note': next_row.at['TimeSinceLastNoteStart'],\n",
    "                'duration': next_row.at['Duration'],\n",
    "                'velocity': next_row.at['Velocity']\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "add_special_tokens = lambda x: torch.cat((torch.tensor([BOS_IDX]), torch.tensor(ast.literal_eval(x)), torch.tensor([EOS_IDX])))\n",
    "add_padding_values = lambda x: torch.cat((torch.tensor([PAD_VALUE]), torch.tensor(ast.literal_eval(x)), torch.tensor([PAD_VALUE])))\n",
    "\n",
    "def collate_fn(batch):\n",
    "    sentences1 = [add_special_tokens(item[0]['sentence']) for item in batch]\n",
    "    time_since_last_note1 = [add_padding_values(item[0]['time_since_last_note']) for item in batch]\n",
    "    duration1 = [add_padding_values(item[0]['duration']) for item in batch]\n",
    "    velocity1 = [add_padding_values(item[0]['velocity'])/100 for item in batch]\n",
    "    sentences2 = [add_special_tokens(item[1]['sentence']) for item in batch]\n",
    "    time_since_last_note2 = [add_padding_values(item[1]['time_since_last_note']) for item in batch]\n",
    "    duration2 = [add_padding_values(item[1]['duration']) for item in batch]\n",
    "    velocity2 = [add_padding_values(item[1]['velocity'])/100 for item in batch]\n",
    "\n",
    "    # Pad them to the same length per batch\n",
    "    sentences1 = pad_sequence(sentences1, batch_first=True, padding_value=PAD_IDX)\n",
    "    time_since_last_note1 = pad_sequence(time_since_last_note1, batch_first=True, padding_value=PAD_VALUE).unsqueeze(-1)\n",
    "    duration1 = pad_sequence(duration1, batch_first=True, padding_value=PAD_VALUE).unsqueeze(-1)\n",
    "    velocity1 = pad_sequence(velocity1, batch_first=True, padding_value=PAD_VALUE).unsqueeze(-1)\n",
    "    extra1 = torch.cat([time_since_last_note1, duration1, velocity1], dim=-1)\n",
    "\n",
    "    sentences2 = pad_sequence(sentences2, batch_first=True, padding_value=PAD_IDX)\n",
    "    time_since_last_note2 = pad_sequence(time_since_last_note2, batch_first=True, padding_value=PAD_VALUE).unsqueeze(-1)\n",
    "    duration2 = pad_sequence(duration2, batch_first=True, padding_value=PAD_VALUE).unsqueeze(-1)\n",
    "    velocity2 = pad_sequence(velocity2, batch_first=True, padding_value=PAD_VALUE).unsqueeze(-1)\n",
    "    extra2 = torch.cat([time_since_last_note2, duration2, velocity2], dim=-1)\n",
    "\n",
    "    return (sentences1, extra1), (sentences2, extra2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MidiDataset()\n",
    "train_split = int(len(dataset) * TRAIN_SPLIT)\n",
    "train_dataset, val_dataset = random_split(dataset, [train_split, len(dataset) - train_split])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "NUM_TRAINING_STEPS = len(train_dataset) // BATCH_SIZE * NUM_EPOCHS\n",
    "NUM_WARMUP_STEPS = NUM_TRAINING_STEPS // NUM_EPOCHS # Use 1 epoch for warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MidiEmbeddingConfig(PositionEmbeddingConfig):\n",
    "    pitch_size: int\n",
    "    dropout: float\n",
    "\n",
    "\n",
    "@register_positional_embedding(\"midi\", MidiEmbeddingConfig)\n",
    "class MidiEmbedding(PositionEmbedding):\n",
    "    def __init__(self, dim_model: int, seq_len: int, pitch_size: int, dropout: float = 0.0, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.dim_model = dim_model\n",
    "        self.seq_len = seq_len\n",
    "        self.pitch_size = pitch_size\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        self.position_embeddings = nn.Embedding(seq_len, self.dim_model)\n",
    "        self.pitch_embeddings = nn.Embedding(\n",
    "            self.pitch_size, self.dim_model - 3)\n",
    "\n",
    "        self.position_ids: Optional[torch.Tensor] = None\n",
    "\n",
    "    def init_weights(self, gain: float = 1.0):\n",
    "        torch.nn.init.normal_(self.position_embeddings.weight, std=0.02 * gain)\n",
    "        torch.nn.init.normal_(self.pitch_embeddings.weight, std=0.02 * gain)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        sentence = x[0]\n",
    "        extra = x[1]\n",
    "\n",
    "        position_ids = torch.arange(sentence.shape[1], dtype=torch.long, device=sentence.device)[\n",
    "            None, :\n",
    "        ].repeat(sentence.shape[0], 1)\n",
    "\n",
    "        pitch_token = self.pitch_embeddings(sentence)\n",
    "\n",
    "        x = torch.cat([pitch_token, extra], dim=-1)\n",
    "        pos = self.position_embeddings(position_ids)\n",
    "\n",
    "        X = x + pos\n",
    "        X = self.dropout(X)\n",
    "\n",
    "        return X\n",
    "\n",
    "\n",
    "class MidiTransformer(nn.Module):\n",
    "    def __init__(self, model_config) -> None:\n",
    "        super().__init__()\n",
    "        self.dim_model = model_config[1]['dim_model']\n",
    "        self.model_config = xFormerConfig(model_config)\n",
    "        self.transformer = xFormer.from_config(self.model_config)\n",
    "        self.generator = nn.Sequential(\n",
    "            nn.Linear(self.dim_model, self.dim_model*2), \n",
    "            nn.LeakyReLU(), \n",
    "            nn.Linear(self.dim_model*2, model_config[1]['position_encoding_config']['pitch_size']))\n",
    "        self.extra_generator = nn.Sequential(\n",
    "            nn.Linear(self.dim_model, self.dim_model*2), \n",
    "            nn.Linear(self.dim_model*2, 3))  # [time_since_last_note, duration, velocity]\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
    "        memory = self.encode(src, src_mask)\n",
    "        out = self.decode(tgt, memory, tgt_mask)\n",
    "        return self.generator(out), self.extra_generator(out)\n",
    "\n",
    "    def encode(self, src, src_mask=None):\n",
    "        encoders = self.transformer.encoders\n",
    "        memory = src[:]\n",
    "        if isinstance(encoders, torch.nn.ModuleList):\n",
    "            for encoder in encoders:\n",
    "                memory = encoder(memory, input_mask=src_mask)\n",
    "        else:\n",
    "            if self.transformer.rev_enc_pose_encoding:\n",
    "                memory = self.transformer.rev_enc_pose_encoding(src)\n",
    "\n",
    "            # Reversible Encoder\n",
    "            x = torch.cat([memory, memory], dim=-1)\n",
    "\n",
    "            # Apply the optional input masking\n",
    "            if src_mask is not None:\n",
    "                if x.dim() - src_mask.dim() > 1:\n",
    "                    src_mask.unsqueeze(0)\n",
    "                x += src_mask.unsqueeze(-1)\n",
    "\n",
    "            x = encoders(x)\n",
    "            memory = torch.stack(x.chunk(2, dim=-1)).mean(dim=0)\n",
    "        return memory\n",
    "\n",
    "    def decode(self, tgt, memory, tgt_mask=None):\n",
    "        for decoder in self.transformer.decoders:\n",
    "            tgt = decoder(target=tgt, memory=memory, input_mask=tgt_mask)\n",
    "        return tgt\n",
    "\n",
    "\n",
    "model_config = [\n",
    "    {\n",
    "        \"reversible\": True,  # Reversible encoder can save a lot memory when training\n",
    "        \"block_type\": \"encoder\",\n",
    "        \"num_layers\": NUM_ENCODER_LAYERS,\n",
    "        \"dim_model\": EMB_SIZE,\n",
    "        \"residual_norm_style\": \"pre\",\n",
    "        \"position_encoding_config\": {\n",
    "            \"name\": \"midi\",  # The vocab type position encoding includes token embedding layer and position encoding layer\n",
    "            \"seq_len\": MAX_LEN,\n",
    "            \"pitch_size\": SRC_VOCAB_SIZE,\n",
    "        },\n",
    "        \"multi_head_config\": {\n",
    "            \"num_heads\": NHEAD,\n",
    "            \"residual_dropout\": 0,\n",
    "            \"attention\": {\n",
    "                \"name\": \"linformer\",\n",
    "                \"dropout\": 0,\n",
    "                \"causal\": False,\n",
    "                \"seq_len\": MAX_LEN,\n",
    "            },\n",
    "        },\n",
    "        \"feedforward_config\": {\n",
    "            \"name\": \"MLP\",\n",
    "            \"dropout\": DROPOUT,\n",
    "            \"activation\": \"relu\",\n",
    "            # Hidden layer dimension is HIDDEN_LAYER_MULTIPLIER times dim_model\n",
    "            \"hidden_layer_multiplier\": HIDDEN_LAYER_MULTIPLIER,\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"reversible\": False,\n",
    "        \"block_type\": \"decoder\",\n",
    "        \"num_layers\": NUM_DECODER_LAYERS,\n",
    "        \"dim_model\": EMB_SIZE,\n",
    "        \"residual_norm_style\": \"pre\",\n",
    "        \"position_encoding_config\": {\n",
    "            \"name\": \"midi\",\n",
    "            \"seq_len\": MAX_LEN,\n",
    "            \"pitch_size\": TGT_VOCAB_SIZE,\n",
    "        },\n",
    "        \"multi_head_config_masked\": {\n",
    "            \"num_heads\": NHEAD,\n",
    "            \"residual_dropout\": 0,\n",
    "            \"attention\": {\n",
    "                \"name\": \"nystrom\",\n",
    "                \"dropout\": 0,\n",
    "                \"causal\": True,  # Causal attention is used to prevent the decoder from attending the future tokens in the target sequences\n",
    "                \"seq_len\": MAX_LEN,\n",
    "            },\n",
    "        },\n",
    "        \"multi_head_config_cross\": {\n",
    "            \"num_heads\": NHEAD,\n",
    "            \"residual_dropout\": 0,\n",
    "            \"attention\": {\n",
    "                \"name\": \"favor\",\n",
    "                \"dropout\": 0,\n",
    "                \"causal\": False,\n",
    "                \"seq_len\": MAX_LEN,\n",
    "            },\n",
    "        },\n",
    "        \"feedforward_config\": {\n",
    "            \"name\": \"MLP\",\n",
    "            \"dropout\": DROPOUT,\n",
    "            \"activation\": \"relu\",\n",
    "            \"hidden_layer_multiplier\": HIDDEN_LAYER_MULTIPLIER,\n",
    "        },\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Params: 0.98 M MidiTransformer(\n",
      "  (transformer): xFormer(\n",
      "    (rev_enc_pose_encoding): MidiEmbedding(\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (position_embeddings): Embedding(256, 64)\n",
      "      (pitch_embeddings): Embedding(131, 61)\n",
      "    )\n",
      "    (encoders): ReversibleSequence(\n",
      "      (blocks): ModuleList(\n",
      "        (0-5): 6 x ReversibleBlock(\n",
      "          (f): Deterministic(\n",
      "            (net): PreNorm(\n",
      "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "              (sublayer): MultiHeadDispatch(\n",
      "                (attention): LinformerAttention(\n",
      "                  (E): Linear(in_features=256, out_features=64, bias=False)\n",
      "                  (F): Linear(in_features=256, out_features=64, bias=False)\n",
      "                  (attn_drop): Dropout(p=0, inplace=False)\n",
      "                )\n",
      "                (in_proj_container): InputProjection(\n",
      "                  (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "                  (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "                  (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "                )\n",
      "                (resid_drop): Dropout(p=0, inplace=False)\n",
      "                (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (g): Deterministic(\n",
      "            (net): PreNorm(\n",
      "              (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "              (sublayer): MLP(\n",
      "                (mlp): Sequential(\n",
      "                  (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "                  (1): ReLU()\n",
      "                  (2): Dropout(p=0.2, inplace=False)\n",
      "                  (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "                  (4): Dropout(p=0.2, inplace=False)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoders): ModuleList(\n",
      "      (0): xFormerDecoderBlock(\n",
      "        (pose_encoding): MidiEmbedding(\n",
      "          (dropout): Dropout(p=0.0, inplace=False)\n",
      "          (position_embeddings): Embedding(256, 64)\n",
      "          (pitch_embeddings): Embedding(131, 61)\n",
      "        )\n",
      "        (wrap_att): Residual(\n",
      "          (layer): PreNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (sublayer): MultiHeadDispatch(\n",
      "              (attention): NystromAttention(\n",
      "                (attn_drop): Dropout(p=0, inplace=False)\n",
      "                (landmark_pooling): AvgPool()\n",
      "              )\n",
      "              (in_proj_container): InputProjection(\n",
      "                (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "              )\n",
      "              (resid_drop): Dropout(p=0, inplace=False)\n",
      "              (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (wrap_cross): Residual(\n",
      "          (layer): PreNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (sublayer): MultiHeadDispatch(\n",
      "              (attention): FavorAttention(\n",
      "                (attn_drop): Dropout(p=0, inplace=True)\n",
      "                (feature_map): SMReg()\n",
      "              )\n",
      "              (in_proj_container): InputProjection(\n",
      "                (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "              )\n",
      "              (resid_drop): Dropout(p=0, inplace=False)\n",
      "              (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (wrap_ff): Residual(\n",
      "          (layer): PreNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (sublayer): MLP(\n",
      "              (mlp): Sequential(\n",
      "                (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "                (1): ReLU()\n",
      "                (2): Dropout(p=0.2, inplace=False)\n",
      "                (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "                (4): Dropout(p=0.2, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (1-5): 5 x xFormerDecoderBlock(\n",
      "        (wrap_att): Residual(\n",
      "          (layer): PreNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (sublayer): MultiHeadDispatch(\n",
      "              (attention): NystromAttention(\n",
      "                (attn_drop): Dropout(p=0, inplace=False)\n",
      "                (landmark_pooling): AvgPool()\n",
      "              )\n",
      "              (in_proj_container): InputProjection(\n",
      "                (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "              )\n",
      "              (resid_drop): Dropout(p=0, inplace=False)\n",
      "              (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (wrap_cross): Residual(\n",
      "          (layer): PreNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (sublayer): MultiHeadDispatch(\n",
      "              (attention): FavorAttention(\n",
      "                (attn_drop): Dropout(p=0, inplace=True)\n",
      "                (feature_map): SMReg()\n",
      "              )\n",
      "              (in_proj_container): InputProjection(\n",
      "                (q_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (k_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "                (v_proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "              )\n",
      "              (resid_drop): Dropout(p=0, inplace=False)\n",
      "              (proj): Linear(in_features=64, out_features=64, bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (wrap_ff): Residual(\n",
      "          (layer): PreNorm(\n",
      "            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "            (sublayer): MLP(\n",
      "              (mlp): Sequential(\n",
      "                (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "                (1): ReLU()\n",
      "                (2): Dropout(p=0.2, inplace=False)\n",
      "                (3): Linear(in_features=256, out_features=64, bias=True)\n",
      "                (4): Dropout(p=0.2, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (generator): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Linear(in_features=128, out_features=131, bias=True)\n",
      "  )\n",
      "  (extra_generator): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=128, bias=True)\n",
      "    (1): Linear(in_features=128, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = MidiTransformer(model_config=model_config)\n",
    "print(f'Num Params: {sum(p.numel() for p in model.parameters() if p.requires_grad)/1e6:.2f} M', model)\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "cross_entropy = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "mae = nn.L1Loss()\n",
    "# optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "optimizer = Adafactor(model.parameters(), lr=LEARNING_RATE, scale_parameter=False, relative_step=False)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=NUM_WARMUP_STEPS, num_training_steps=NUM_TRAINING_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_PRETRAINED:\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(logits, targets, ignore_index=None):\n",
    "    # Get the index of the highest logit value for each example\n",
    "    predictions = torch.argmax(logits, dim=1)\n",
    "    # Compare predictions to targets\n",
    "    correct = (predictions == targets)\n",
    "    # Ignore specified index\n",
    "    if ignore_index is not None:\n",
    "        mask = (targets != ignore_index)\n",
    "        correct = correct[mask]\n",
    "    # Calculate accuracy\n",
    "    acc = correct.float().mean()\n",
    "    return acc.item()\n",
    "\n",
    "def repeating_penalty(logits, targets, ignore_index=PAD_IDX):\n",
    "    \"\"\"\n",
    "    Calculates the penalty for repeating incorrect predictions.\n",
    "\n",
    "    Args:\n",
    "        logits (torch.Tensor): The model's output logits.\n",
    "        targets (torch.Tensor): The target values.\n",
    "        ignore_index (int, optional): Specifies a target value that is ignored when\n",
    "            calculating the penalty. If `None`, no target value is ignored.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The penalty for repeating incorrect predictions.\n",
    "    \"\"\"\n",
    "    # Get the index of the highest logit value for each example\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    # Compare predictions to targets\n",
    "    incorrect = (predictions != targets.squeeze(-1))\n",
    "\n",
    "    # If ignore_index is specified, ignore those targets\n",
    "    if ignore_index is not None:\n",
    "        ignored = (targets == ignore_index)\n",
    "        incorrect[ignored] = False\n",
    "\n",
    "    # Calculate penalty for repeating incorrect predictions\n",
    "    penalty = (incorrect[:, 1:] & (predictions[:, 1:] == predictions[:, :-1])).float().sum()/(targets.shape[0] * targets.shape[1])\n",
    "    return penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_step = 0 # Used to trace global steps and plot in tensorboard\n",
    "put_tuple_to_device = lambda x: tuple(x.to(DEVICE) for x in x)\n",
    "create_mask = lambda x: x != PAD_IDX\n",
    "writer = SummaryWriter()\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    model.train()\n",
    "    for src, tgt in tqdm(train_dataloader, desc=\"Train\"):\n",
    "        src = put_tuple_to_device(src)\n",
    "        tgt = put_tuple_to_device(tgt)\n",
    "        tgt_input = (tgt[0][:, :-1], tgt[1][:, :-1])\n",
    "        src_mask, tgt_mask = create_mask(src[0]), create_mask(tgt_input[0])\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits, extra = model(src, tgt_input, src_mask, tgt_mask)\n",
    "        tgt_out = tgt[0][:, 1:]\n",
    "        \n",
    "        loss_c = cross_entropy(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "        loss_h = mae(tgt[1][:, 1:].reshape(-1), extra.reshape(-1))\n",
    "        loss_repeating = repeating_penalty(logits, tgt_out)\n",
    "        loss = loss_c + loss_h + loss_repeating * REPEATING_PENALTY\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            acc = accuracy(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1), ignore_index=PAD_IDX)\n",
    "\n",
    "        # Add tracing to tensorboard\n",
    "        global training_step\n",
    "        writer.add_scalar(\"Train/CrossEntropy\", loss_c.item(), training_step)\n",
    "        writer.add_scalar(\"Train/Accuracy\", acc, training_step)\n",
    "        writer.add_scalar(\"Train/MAE\", loss_h.item(), training_step)\n",
    "        writer.add_scalar(\"Train/Repeating\", loss_repeating.item(), training_step)\n",
    "        writer.add_scalar(\"Train/Total\", loss.item(), training_step)\n",
    "        writer.add_scalar(\"Learning Rate\", optimizer.param_groups[0][\"lr\"], training_step)\n",
    "        training_step += 1\n",
    "\n",
    "def eval_epoch(model):\n",
    "    model.eval()\n",
    "    total_losses = 0\n",
    "    total_losses_c = 0\n",
    "    total_losses_h = 0\n",
    "    total_losses_repeating = 0\n",
    "    total_acc = 0\n",
    "    total_steps = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in tqdm(val_dataloader, desc=\"Validation\"):\n",
    "            src = put_tuple_to_device(src)\n",
    "            tgt = put_tuple_to_device(tgt)\n",
    "            tgt_input = (tgt[0][:, :-1], tgt[1][:, :-1])\n",
    "            src_mask, tgt_mask = create_mask(src[0]), create_mask(tgt_input[0])\n",
    "\n",
    "            logits, extra = model(src, tgt_input, src_mask, tgt_mask)\n",
    "            tgt_out = tgt[0][:, 1:]\n",
    "            loss_c = cross_entropy(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
    "            loss_h = mae(tgt[1][:, 1:].reshape(-1), extra.reshape(-1))\n",
    "            loss_repeating = repeating_penalty(logits, tgt_out)\n",
    "            loss = loss_c + loss_h + loss_repeating * REPEATING_PENALTY\n",
    "            total_losses += loss.item()\n",
    "            total_losses_c += loss_c.item()\n",
    "            total_losses_h += loss_h.item()\n",
    "            total_losses_repeating += loss_repeating.item()\n",
    "            total_steps += 1\n",
    "            total_acc += accuracy(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1), ignore_index=PAD_IDX)\n",
    "\n",
    "        global training_step\n",
    "        writer.add_scalar(\"Val/CrossEntropy\", total_losses_c/total_steps, training_step)\n",
    "        writer.add_scalar(\"Val/Accuracy\", total_acc/total_steps, training_step)\n",
    "        writer.add_scalar(\"Val/MAE\", total_losses_h/total_steps, training_step)\n",
    "        writer.add_scalar(\"Val/Repeating\", total_losses_repeating/total_steps, training_step)\n",
    "        writer.add_scalar(\"Val/Total\", total_losses/total_steps, training_step)\n",
    "    return total_losses / total_steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "Start Epoch 1/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "895fa6877eaa431a9922d79c4accef3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/5170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30496612f12145d7aa0aec3e91b54fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/273 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 1/7 in 975.01s with eval loss 8.24\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "Start Epoch 2/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb81e82acd7a4be88f11f4935e28b10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/5170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e4637af73804cbb88cf6914b6197100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/273 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 2/7 in 970.43s with eval loss 4.60\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "Start Epoch 3/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f61e1d2ae14df69be0d9143acebb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/5170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427e6732c2b94f318f30a21409bf6769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/273 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 3/7 in 967.43s with eval loss 4.13\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "Start Epoch 4/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe4259cf6714253adf6cd1d62ce877b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/5170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e582dbe09d646f4b155671cec5fe29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/273 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 4/7 in 971.17s with eval loss 3.89\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "Start Epoch 5/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50ec1405b454ee1914d1a2827abb19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/5170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f337f53d8d34484e88c52de818b08173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/273 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 5/7 in 971.84s with eval loss 3.80\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "Start Epoch 6/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f3bcc08470b4d0ca3989982d7c4fbf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/5170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15290dea80c4dbb8c45527262525c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/273 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 6/7 in 978.92s with eval loss 3.73\n",
      "----------------------------------------------------------------\n",
      "----------------------------------------------------------------\n",
      "Start Epoch 7/7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c4819515dd0464eb8e54a7826613dce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/5170 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab638913f92143978a949ce6c83e5b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation:   0%|          | 0/273 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Epoch 7/7 in 984.23s with eval loss 3.66\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = timer()\n",
    "    print(\"-\" * 64)\n",
    "    print(f\"Start Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    train_epoch(model, optimizer)\n",
    "    end_time = timer()\n",
    "    eval_loss = eval_epoch(model)\n",
    "    writer.flush()\n",
    "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    print(f\"End Epoch {epoch + 1}/{NUM_EPOCHS} in {end_time - start_time:.2f}s with eval loss {eval_loss:.2f}\")\n",
    "    print(\"-\" * 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Midi Data: tensor([[129,  55,  57,  67,  69,  61,  63,  69,  67,  79,  81,  27,  39,  41,\n",
      "          29,  43,  31,  49,  61,  63,  49,  45,  33,  49,  48,  36,  63,  61,\n",
      "          49,  44,  32,  49,  47,  35,  63,  61, 130, 128, 128, 128, 128, 128,\n",
      "         128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "         128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,\n",
      "         128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]])\n",
      "Predicted Next Midi Sentence: tensor([[129,  49,  37,  49,  39,  51,  49,  37,  49,  39,  51,  49,  37,  49,\n",
      "          39,  51,  49,  37,  49,  39,  51,  49,  37,  49,  39,  51,  49,  39,\n",
      "          49,  39,  49,  51,  49, 130]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def greedy_decode(model, src, src_mask=None, max_len=MAX_LEN, start_symbol=BOS_IDX):\n",
    "    src = put_tuple_to_device(src)\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys_token = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    ys_extra = torch.ones(1, 1, 3).fill_(PAD_VALUE).type(torch.long).to(DEVICE)\n",
    "    ys = (ys_token, ys_extra)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(ys, memory)\n",
    "        prob = model.generator(out[:, -1, :])\n",
    "        extra = model.extra_generator(out[:, -1, :]).unsqueeze(0)\n",
    "        _, next_token = torch.max(prob, dim=1)\n",
    "        next_token = next_token.item()\n",
    "        ys_token = torch.cat([ys_token, torch.ones(1, 1).type_as(src[0].data).fill_(next_token)], dim=1)\n",
    "        ys_extra = torch.cat([ys_extra, extra], dim=1)\n",
    "        ys = (ys_token, ys_extra)\n",
    "        if next_token == EOS_IDX:\n",
    "            break\n",
    "    return ys\n",
    "\n",
    "\n",
    "def predict_next_midi_sentence(model, src):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        mask = create_mask(src[0]).to(DEVICE)\n",
    "        result = greedy_decode(model, src, mask)\n",
    "    return result\n",
    "\n",
    "\n",
    "src, trg = next(iter(val_dataloader))\n",
    "src_test = (src[0][0].unsqueeze(0), src[1][0].unsqueeze(0))\n",
    "print(f'Input Midi Data: {src_test[0]}')\n",
    "midi_next = predict_next_midi_sentence(model, src_test)\n",
    "print(f'Predicted Next Midi Sentence: {midi_next[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
